<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Models · PolieDRO.jl</title><meta name="title" content="Models · PolieDRO.jl"/><meta property="og:title" content="Models · PolieDRO.jl"/><meta property="twitter:title" content="Models · PolieDRO.jl"/><meta name="description" content="Documentation for PolieDRO.jl."/><meta property="og:description" content="Documentation for PolieDRO.jl."/><meta property="twitter:description" content="Documentation for PolieDRO.jl."/><meta property="og:url" content="https://joaoqcouto.github.io/PolieDRO.jl/models/"/><meta property="twitter:url" content="https://joaoqcouto.github.io/PolieDRO.jl/models/"/><link rel="canonical" href="https://joaoqcouto.github.io/PolieDRO.jl/models/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">PolieDRO.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Introduction</a></li><li class="is-active"><a class="tocitem" href>Models</a><ul class="internal"><li><a class="tocitem" href="#Hinge-Loss"><span>Hinge Loss</span></a></li><li><a class="tocitem" href="#Logistic-Loss"><span>Logistic Loss</span></a></li><li><a class="tocitem" href="#Mean-Squared-Error"><span>Mean Squared Error</span></a></li><li class="toplevel"><a class="tocitem" href="#Implementing-a-custom-model"><span>Implementing a custom model</span></a></li></ul></li><li><a class="tocitem" href="../reference/">API reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Models</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Models</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/joaoqcouto/PolieDRO.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/joaoqcouto/PolieDRO.jl/blob/main/docs/src/models.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><ul></ul><h1 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h1><p>PolieDRO is a framework for classification and regression using distributionally robust optimization in a data-driven manner, avoiding the use of hyperparameters. From the input data, nested convex hulls are constructed and confidence intervals associated with each hull&#39;s coverage probability are calculated.</p><p>To calculate the confidence intervals for the hulls&#39; associated probabilities, a significance level can be chosen by the user, with the default value being 5%.</p><p><img src="https://github.com/user-attachments/assets/45cedbf1-fa43-42ec-bf4d-065e90da650b" alt="Convex hulls"/></p><p>With the information of the vertices&#39; convex hulls and their associated probabilities, it is then possible to construct the DRO problem developed in the framework as seen below for a given convex loss function <span>$h(W;\beta)$</span>:</p><p class="math-container">\[\min_{\beta, \lambda,\kappa} \sum_{i \in F} (\kappa_i \overline{p_i} - \lambda_i \underline{p_i})\]</p><p class="math-container">\[\text{s.t.} \quad h(W;\beta) - \sum_{l \in A(i)} (\kappa_l - \lambda_l) \leq 0, \quad \forall j \in V_i, \forall i \in F\]</p><p class="math-container">\[\lambda_i \geq 0, \forall i \in F\]</p><p class="math-container">\[\kappa_i \geq 0, \forall i \in F\]</p><p class="math-container">\[\beta \in B\]</p><p>Where <span>$F$</span> is the set of convex hulls of the observations, <span>$V_i$</span> is the set of vertices present in each convex hull <span>$i \in F$</span> and <span>$\underline{p_i}$</span>, <span>$\overline{p_i}$</span> are the confidence intervals for each hull&#39;s coverage probability.</p><p>With this in hand, three loss functions used in common machine learning methods were applied to the framework.</p><h2 id="Hinge-Loss"><a class="docs-heading-anchor" href="#Hinge-Loss">Hinge Loss</a><a id="Hinge-Loss-1"></a><a class="docs-heading-anchor-permalink" href="#Hinge-Loss" title="Permalink"></a></h2><p>The hinge loss function is a margin-based loss function commonly used in classification tasks with the support vector machine (SVM). It linearly penalizes a misclassification of an observation. Below is the formulation of the PolieDRO problem with the use of the hinge loss function as <span>$h(W;\beta)$</span>:</p><p class="math-container">\[\min_{\beta, \lambda,\kappa, \eta} \sum_{i \in F} (\kappa_i \overline{p_i} - \lambda_i \underline{p_i})\]</p><p class="math-container">\[\text{s.t.} \quad \eta_j - \sum_{l \in A(i)} (\kappa_l - \lambda_l) \leq 0, \quad \forall j \in V_i, \forall i \in F\]</p><p class="math-container">\[\eta_j \geq 1 - y_j(\beta_1^Tx_j - \beta_0), \forall j \in V_i, i \in F\]</p><p class="math-container">\[\eta_j \geq 0, \forall j \in V_i, i \in F\]</p><p class="math-container">\[\lambda_i \geq 0, \forall i \in F\]</p><p class="math-container">\[\kappa_i \geq 0, \forall i \in F\]</p><p>Having solved the problem, we have in hand the parameters <span>$\beta$</span>. It is then possible to evaluate a given point <span>$x$</span> as below:</p><p class="math-container">\[\hat{y} = \beta_1^Tx - \beta_0\]</p><p>This output is based on the hinge loss function, meaning a value above zero indicates the point is classified as the class &#39;1&#39;, while a value below zero indicate a classification of &#39;-1&#39; (values between 0 and 1 are close to the boundary between classes).</p><h3 id="Usage-in-PolieDRO.jl"><a class="docs-heading-anchor" href="#Usage-in-PolieDRO.jl">Usage in PolieDRO.jl</a><a id="Usage-in-PolieDRO.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Usage-in-PolieDRO.jl" title="Permalink"></a></h3><p>To use the Hinge Loss PolieDRO model in a classification problem, a linear solver for JuMP is needed. The example below is using <a href="https://github.com/jump-dev/HiGHS.jl">HiGHS</a>, an open-source linear optimization solver.</p><p>To load an example dataset, the package <a href="https://github.com/JackDunnNZ/UCIData.jl">UCIData.jl</a> is used to load it directly in Julia as a Dataframe. This classification example uses <a href="https://archive.ics.uci.edu/dataset/277/thoracic+surgery+data">thoracic surgery data</a>.</p><pre><code class="language-julia hljs">using PolieDRO
using UCIData, HiGHS

df = UCIData.dataset(&quot;thoracic-surgery&quot;)</code></pre><p>To use this dataset in PolieDRO, some basic treatment is applied. The data is normalized, category columns are encoded, missing values are removed. The dataset is also split into a training and test set for an out-of-sample evaluation.</p><p>Since the models currently only take matrices, the dataframes are also converted.</p><pre><code class="language-julia hljs"># this function can be found as written within the test directory of this repository
Xtrain, Xtest, ytrain, ytest = treat_df(df; classification=true)

Xtrain_m = Matrix{Float64}(Xtrain)
Xtest_m = Matrix{Float64}(Xtest)</code></pre><p>The model is then built using the training data. It is during this time that the convex hulls are calculated for the data. The loss function is also specified as hinge loss as a parameter to build the model. A custom significance level can be chosen, here the default value of 0.05 is used.</p><p>Besides the model, the function also returns an evaluator function. It can be used to evaluate points with the optimized model.</p><pre><code class="language-julia hljs">model, evaluator = PolieDRO.build_model(Xtrain_m, ytrain, PolieDRO.hinge_loss)</code></pre><p>Now the model can be solved using a linear solver and the test set evaluated with the evaluator function:</p><pre><code class="language-julia hljs">PolieDRO.solve_model!(model, HiGHS.Optimizer; silent=true)
ytest_eval = evaluator(model, Xtest_m)</code></pre><p>As said before, this outputs values relative to the hinge loss function. Below is an evaluation example where we take values above 0 as being classified as &#39;1&#39;:</p><pre><code class="language-julia hljs">ytest_eval_abs = [yp &gt;= 0.0 ? 1.0 : -1.0 for yp in ytest_eval]
acc_poliedro = sum(ytest_eval_abs.==ytest)*100/length(ytest)</code></pre><p>For this example, the PolieDRO Hinge Loss model achieves an accuracy of 85.1%.</p><h2 id="Logistic-Loss"><a class="docs-heading-anchor" href="#Logistic-Loss">Logistic Loss</a><a id="Logistic-Loss-1"></a><a class="docs-heading-anchor-permalink" href="#Logistic-Loss" title="Permalink"></a></h2><p>The logistic loss is used to estimate the probability of a data point being in a certain category. In a binary setting, data points classified as &#39;1&#39; are expected to have a probability evaluated near 1 while data points classified as &#39;-1&#39; are expected to have a probability near zero. Using this loss function as <span>$h(W;\beta)$</span> we arrive in the formulation below:</p><p class="math-container">\[\min_{\beta, \lambda,\kappa} \sum_{i \in F} (\kappa_i \overline{p_i} - \lambda_i \underline{p_i})\]</p><p class="math-container">\[\text{s.t.} \quad \log(1+e^{-y_j(\beta_0 + \beta_1^Tx_j)}) - \sum_{l \in A(i)} (\kappa_l - \lambda_l) \leq 0, \quad \forall j \in V_i, \forall i \in F\]</p><p class="math-container">\[\lambda_i \geq 0, \forall i \in F\]</p><p class="math-container">\[\kappa_i \geq 0, \forall i \in F\]</p><p>The parameters <span>$\beta$</span> can be used to evaluate a given point <span>$x$</span> as below:</p><p class="math-container">\[\hat{y} = \frac{e^{\beta_0 + \beta_1^Tx}}{1+e^{\beta_0 + \beta_1^Tx}}\]</p><p>As said above, this logistic loss output is near 1 when a point is classified as &#39;1&#39; and near 0 when &#39;-1&#39;. One could then choose something such as 0.5 to decide which class to assume.</p><h3 id="Usage-in-PolieDRO.jl-2"><a class="docs-heading-anchor" href="#Usage-in-PolieDRO.jl-2">Usage in PolieDRO.jl</a><a class="docs-heading-anchor-permalink" href="#Usage-in-PolieDRO.jl-2" title="Permalink"></a></h3><p>To use the Logistic Loss PolieDRO model in a classification problem, a nonlinear solver for JuMP is needed. The example below is using <a href="https://github.com/jump-dev/Ipopt.jl">Ipopt</a>, an open-source nonlinear optimization solver.</p><p>To load an example dataset, the package <a href="https://github.com/JackDunnNZ/UCIData.jl">UCIData.jl</a> is used to load it directly in Julia as a Dataframe. This classification example uses <a href="https://archive.ics.uci.edu/dataset/277/thoracic+surgery+data">thoracic surgery data</a>.</p><pre><code class="language-julia hljs">using PolieDRO
using UCIData, Ipopt

df = UCIData.dataset(&quot;thoracic-surgery&quot;)</code></pre><p>To use this dataset in PolieDRO, some basic treatment is applied. The data is normalized, category columns are encoded, missing values are removed. The dataset is also split into a training and test set for an out-of-sample evaluation.</p><p>Since the models currently only take matrices, the dataframes are also converted.</p><pre><code class="language-julia hljs"># this function can be found as written within the test directory of this repository
Xtrain, Xtest, ytrain, ytest = treat_df(df; classification=true)

Xtrain_m = Matrix{Float64}(Xtrain)
Xtest_m = Matrix{Float64}(Xtest)</code></pre><p>The model is then built using the training data. It is during this time that the convex hulls are calculated for the data. The loss function is also specified as logistic loss as a parameter to build the model. A custom significance level can be chosen, here the default value of 0.05 is used.</p><pre><code class="language-julia hljs">model, evaluator = PolieDRO.build_model(Xtrain_m, ytrain, PolieDRO.logistic_loss)</code></pre><p>Now the model can be solved using a nonlinear solver and the test set evaluated:</p><pre><code class="language-julia hljs">PolieDRO.solve_model!(model, Ipopt.Optimizer; silent=true)
ytest_eval = evaluator(model, Xtest_m)</code></pre><p>This outputs values relative to the logistic loss function, in other words the probability of a point being in the class &#39;1&#39;. Below is an evaluation example where we take values above 0.5 as being classified as &#39;1&#39;:</p><pre><code class="language-julia hljs">ytest_eval_abs = [yp &gt;= 0.5 ? 1.0 : -1.0 for yp in ytest_eval]
acc_poliedro = sum(ytest_eval_abs.==ytest)*100/length(ytest)</code></pre><p>For this example, the PolieDRO Logistic Loss model achieves an accuracy of 83.0%.</p><h2 id="Mean-Squared-Error"><a class="docs-heading-anchor" href="#Mean-Squared-Error">Mean Squared Error</a><a id="Mean-Squared-Error-1"></a><a class="docs-heading-anchor-permalink" href="#Mean-Squared-Error" title="Permalink"></a></h2><p>The mean squared error (MSE) is a distance-based error metric commonly seen in linear regression models, such as the LASSO regression. Using it in the PolieDRO framework, the formulation we arrive at is:</p><p class="math-container">\[\min_{\beta, \lambda,\kappa} \sum_{i \in F} (\kappa_i \overline{p_i} - \lambda_i \underline{p_i})\]</p><p class="math-container">\[\text{s.t.} \quad (y_j - (\beta_0 + \beta_1^Tx_j))^2 - \sum_{l \in A(i)} (\kappa_l - \lambda_l) \leq 0, \quad \forall j \in V_i, \forall i \in F\]</p><p class="math-container">\[\lambda_i \geq 0, \forall i \in F\]</p><p class="math-container">\[\kappa_i \geq 0, \forall i \in F\]</p><p>A point <span>$x$</span> can then be evaluated as below:</p><p class="math-container">\[\hat{y} = \beta_0 + \beta_1^Tx\]</p><h3 id="Usage-in-PolieDRO.jl-3"><a class="docs-heading-anchor" href="#Usage-in-PolieDRO.jl-3">Usage in PolieDRO.jl</a><a class="docs-heading-anchor-permalink" href="#Usage-in-PolieDRO.jl-3" title="Permalink"></a></h3><p>To use the MSE PolieDRO model in a regression problem, a nonlinear solver for JuMP is needed. The example below is using <a href="https://github.com/jump-dev/Ipopt.jl">Ipopt</a>, an open-source nonlinear optimization solver.</p><p>To load an example dataset, the package <a href="https://github.com/JackDunnNZ/UCIData.jl">UCIData.jl</a> is used to load it directly in Julia as a Dataframe. This regression example uses <a href="https://archive.ics.uci.edu/dataset/10/automobile">automobile data</a>.</p><pre><code class="language-julia hljs">using PolieDRO
using UCIData, Ipopt

df = UCIData.dataset(&quot;automobile&quot;)</code></pre><p>To use this dataset in PolieDRO, some basic treatment is applied. The data is normalized, category columns are encoded, missing values are removed. The dataset is also split into a training and test set for an out-of-sample evaluation.</p><p>Since the models currently only take matrices, the dataframes are also converted.</p><pre><code class="language-julia hljs"># this function can be found as written within the test directory of this repository
Xtrain, Xtest, ytrain, ytest = treat_df(df; classification=false)

Xtrain_m = Matrix{Float64}(Xtrain)
Xtest_m = Matrix{Float64}(Xtest)</code></pre><p>The model is then built using the training data. It is during this time that the convex hulls are calculated for the data. The loss function is also specified as MSE as a parameter to build the model. A custom significance level can be chosen, here the default value of 0.05 is used.</p><pre><code class="language-julia hljs">model, evaluator = PolieDRO.build_model(Xtrain_m, ytrain, PolieDRO.mse_loss)</code></pre><p>Now the model can be solved using a nonlinear solver and the test set evaluated:</p><pre><code class="language-julia hljs">PolieDRO.solve_model!(model, Ipopt.Optimizer; silent=true)
ytest_eval = evaluator(model, Xtest_m)</code></pre><p>Since this is a regression problem, these values can then be directly used as evaluations. Below we calculate the mean squared error in the test set:</p><pre><code class="language-julia hljs">mse_poliedro = mean([(ytest_eval[i] - ytest[i])^2 for i in eachindex(ytest)])</code></pre><p>For this example, the PolieDRO MSE model achieves a mean squared error of 0.394.</p><h1 id="Implementing-a-custom-model"><a class="docs-heading-anchor" href="#Implementing-a-custom-model">Implementing a custom model</a><a id="Implementing-a-custom-model-1"></a><a class="docs-heading-anchor-permalink" href="#Implementing-a-custom-model" title="Permalink"></a></h1><p>To create a custom model, two functions need to be defined:</p><ul><li>A convex loss function, which will be used in the general model formulation as <span>$h(W;\beta)$</span><ul><li>If the loss function is piecewise linear, it is also possible to use an array of multiple functions, in a way that the loss function will be defined as the maximum of all the given functions. This will avoid making the model nonlinear.</li></ul></li><li>A point evaluator function, which will take a given point <span>$x$</span> and the model&#39;s parameters <span>$\beta$</span> and evaluate <span>$\hat{y}$</span>.</li></ul><h3 id="Example:-MAE-model"><a class="docs-heading-anchor" href="#Example:-MAE-model">Example: MAE model</a><a id="Example:-MAE-model-1"></a><a class="docs-heading-anchor-permalink" href="#Example:-MAE-model" title="Permalink"></a></h3><p>To exemplify the construction of a custom model, we will use the mean absolute error as a distance-based error metric to construct a regression model.</p><p>To use the MAE function in a linear model, it is possible to define two functions instead of one and pass them as an array to the model builder.</p><p>This makes use of the fact that absolute error could be seen as the maximum of positive and negative error, which are both linear. The use of two linear functions instead of a piecewise linear one allows for the use of linear solvers.</p><pre><code class="language-julia hljs"># Positive error
function pos_error(x::Vector{T}, y::T, β0::VariableRef, β1::Vector{VariableRef}) where T&lt;:Float64
    return (y-(β0+sum(β1[k]*x[k] for k in eachindex(β1))))
end
# Negative error
function neg_error(x::Vector{T}, y::T, β0::VariableRef, β1::Vector{VariableRef}) where T&lt;:Float64
    return -(y-(β0+sum(β1[k]*x[k] for k in eachindex(β1))))
end</code></pre><p>Besides that, we need an evaluator function that will use the optimized parameters to evaluate a point <span>$x$</span>.</p><pre><code class="language-julia hljs">function mae_point_evaluator(x::Vector{T}, β0::T, β1::Vector{T}) where T&lt;:Float64
    return β0 + β1&#39;x
end</code></pre><p>The model is then built using the training data. Instead of using a predefined model, we pass the loss functions and the evaluator to the model builder function.</p><pre><code class="language-julia hljs">model, evaluator = PolieDRO.build_model(Xtrain_m, ytrain, [pos_error, neg_error], mae_point_evaluator)</code></pre><p>Now the model can be solved using a linear solver and the test set evaluated:</p><pre><code class="language-julia hljs">PolieDRO.solve_model!(model, HiGHS.Optimizer; silent=true)
ytest_eval = evaluator(model, Xtest_m)</code></pre><p>Since this is a regression problem, these values can then be directly used as evaluations. Below we calculate the mean squared error in the test set:</p><pre><code class="language-julia hljs">mse_poliedro = mean([(ytest_eval[i] - ytest[i])^2 for i in eachindex(ytest)])</code></pre><p>In the automobile dataset, the custom PolieDRO MAE model achieves a mean squared error of 0.220.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Introduction</a><a class="docs-footer-nextpage" href="../reference/">API reference »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.7.0 on <span class="colophon-date" title="Tuesday 24 September 2024 04:38">Tuesday 24 September 2024</span>. Using Julia version 1.10.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
